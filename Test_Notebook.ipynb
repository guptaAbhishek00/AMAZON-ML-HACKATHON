{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c13a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c55ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value  \n",
       "0      500.0 gram  \n",
       "1         1.0 cup  \n",
       "2      0.709 gram  \n",
       "3      0.709 gram  \n",
       "4  1400 milligram  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\datasets\\train.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10551625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_link      0\n",
       "group_id        0\n",
       "entity_name     0\n",
       "entity_value    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28ecf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb88001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263859 entries, 0 to 263858\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   image_link    263859 non-null  object\n",
      " 1   group_id      263859 non-null  int64 \n",
      " 2   entity_name   263859 non-null  object\n",
      " 3   entity_value  263859 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd54ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ae2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# import constants\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import time\n",
    "from time import time as timer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eeb4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}\n",
    "}\n",
    "\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120ed785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def common_mistake(unit):\n",
    "#     if unit in constants.allowed_units:\n",
    "#         return unit\n",
    "#     if unit.replace('ter', 'tre') in constants.allowed_units:\n",
    "#         return unit.replace('ter', 'tre')\n",
    "#     if unit.replace('feet', 'foot') in constants.allowed_units:\n",
    "#         return unit.replace('feet', 'foot')\n",
    "#     return unit\n",
    "\n",
    "# def parse_string(s):\n",
    "#     s_stripped = \"\" if s==None or str(s)=='nan' else s.strip()\n",
    "#     if s_stripped == \"\":\n",
    "#         return None, None\n",
    "#     pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
    "#     if not pattern.match(s_stripped):\n",
    "#         raise ValueError(\"Invalid format in {}\".format(s))\n",
    "#     parts = s_stripped.split(maxsplit=1)\n",
    "#     number = float(parts[0])\n",
    "#     unit = common_mistake(parts[1])\n",
    "#     if unit not in constants.allowed_units:\n",
    "#         raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n",
    "#             unit, s, constants.allowed_units))\n",
    "#     return number, unit\n",
    "\n",
    "\n",
    "# def create_placeholder_image(image_save_path):\n",
    "#     try:\n",
    "#         placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "#         placeholder_image.save(image_save_path)\n",
    "#     except Exception as e:\n",
    "#         return\n",
    "\n",
    "# def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "#     if not isinstance(image_link, str):\n",
    "#         return\n",
    "\n",
    "#     filename = Path(image_link).name\n",
    "#     image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "#     if os.path.exists(image_save_path):\n",
    "#         return\n",
    "\n",
    "#     for _ in range(retries):\n",
    "#         try:\n",
    "#             urllib.request.urlretrieve(image_link, image_save_path)\n",
    "#             return\n",
    "#         except:\n",
    "#             time.sleep(delay)\n",
    "    \n",
    "#     create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
    "    \n",
    "# def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
    "#     if not os.path.exists(download_folder):\n",
    "#         os.makedirs(download_folder)\n",
    "\n",
    "#     if allow_multiprocessing:\n",
    "#         download_image_partial = partial(\n",
    "#             download_image, save_folder=download_folder, retries=3, delay=3)\n",
    "\n",
    "#         with multiprocessing.Pool(60) as pool:\n",
    "#             list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
    "#             pool.close()\n",
    "#             pool.join()\n",
    "#     else:\n",
    "#         for image_link in tqdm(image_links, total=len(image_links)):\n",
    "#             download_image(image_link, save_folder=download_folder, retries=3, delay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26887572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import urllib.request\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# import time\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# # Function to create a black placeholder image in case of failure\n",
    "# def create_placeholder_image(image_save_path):\n",
    "#     try:\n",
    "#         placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "#         placeholder_image.save(image_save_path)\n",
    "#     except Exception as e:\n",
    "#         return\n",
    "\n",
    "# # Function to download a single image\n",
    "# def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "#     if not isinstance(image_link, str):\n",
    "#         return\n",
    "\n",
    "#     filename = Path(image_link).name\n",
    "#     image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "#     if os.path.exists(image_save_path):\n",
    "#         return\n",
    "\n",
    "#     for _ in range(retries):\n",
    "#         try:\n",
    "#             urllib.request.urlretrieve(image_link, image_save_path)\n",
    "#             return\n",
    "#         except:\n",
    "#             time.sleep(delay)\n",
    "    \n",
    "#     # Create a placeholder if the image fails to download\n",
    "#     create_placeholder_image(image_save_path)\n",
    "\n",
    "# # Function to download images using ThreadPoolExecutor (works in Jupyter)\n",
    "# def download_images(image_links, download_folder, max_workers=10):\n",
    "#     if not os.path.exists(download_folder):\n",
    "#         os.makedirs(download_folder)\n",
    "\n",
    "#     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#         list(tqdm(executor.map(lambda link: download_image(link, download_folder), image_links), total=len(image_links)))\n",
    "\n",
    "# # Example usage in Jupyte\n",
    "# download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/imgs\"\n",
    "# image_links = df['image_link'][:500].dropna().tolist()\n",
    "\n",
    "# # Download images using ThreadPoolExecutor\n",
    "# download_images(image_links, download_folder, max_workers=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f089ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Define the folder where the processed images will be saved\n",
    "# processed_folder = r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\imgs\\preimg\"  # Use raw string for paths\n",
    "\n",
    "# # Create the output folder if it does not exist\n",
    "# if not os.path.exists(processed_folder):\n",
    "#     os.makedirs(processed_folder)\n",
    "\n",
    "# # Function to preprocess a single image: resize and normalize\n",
    "# def preprocess_image(image_path, output_path, target_size=(224, 224)):\n",
    "#     try:\n",
    "#         # Open the image\n",
    "#         image = Image.open(image_path)\n",
    "#         # Resize the image to the target size\n",
    "#         image = image.resize(target_size)\n",
    "#         # Convert the image to a numpy array and normalize pixel values to [0, 1]\n",
    "#         image_array = np.array(image) / 255.0\n",
    "#         # Convert the array back to an image and save it\n",
    "#         processed_image = Image.fromarray((image_array * 255).astype(np.uint8))\n",
    "#         processed_image.save(output_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to process image {image_path}: {e}\")\n",
    "\n",
    "# # Set the download folder where images are located\n",
    "# download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/imgs\"\n",
    "\n",
    "# # List all images in the downloaded folder with common extensions\n",
    "# image_paths = list(Path(download_folder).glob(\"*.jpg\")) + \\\n",
    "#               list(Path(download_folder).glob(\"*.jpeg\")) + \\\n",
    "#               list(Path(download_folder).glob(\"*.png\"))  # Adjust patterns for other extensions as needed\n",
    "\n",
    "# # Preprocess and save each image\n",
    "# for image_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
    "#     # Define the output path\n",
    "#     output_path = os.path.join(processed_folder, image_path.name)\n",
    "#     preprocess_image(image_path, output_path)\n",
    "\n",
    "# print(\"Image preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facaf670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytesseract) (10.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7ddf78-fb9d-42be-9ed8-f3fbd26b90ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60986af-4a24-4434-8271-796fd96d79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "# import re\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# from fuzzywuzzy import fuzz\n",
    "\n",
    "# # Specify the path to the Tesseract executable\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path as needed\n",
    "\n",
    "# # Folder containing the original downloaded images\n",
    "# download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/imgs\"\n",
    "\n",
    "# # Load the training data from train.csv\n",
    "# train_csv_path = \"train.csv\"  # Update path as needed\n",
    "# train_data = pd.read_csv(train_csv_path)\n",
    "\n",
    "# # Enhanced OCR function with additional preprocessing steps\n",
    "# def extract_text_from_image(image_path):\n",
    "#     try:\n",
    "#         # Open the image and convert to grayscale\n",
    "#         image = Image.open(image_path).convert('L')\n",
    "        \n",
    "#         # Advanced preprocessing: Resize, invert colors, binarize, and enhance\n",
    "#         image = image.resize((600, 600))  # Larger resize to capture small text\n",
    "#         image = ImageOps.invert(image)  # Invert colors to improve contrast\n",
    "#         image = ImageEnhance.Contrast(image).enhance(3)  # Further increase contrast\n",
    "#         image = image.filter(ImageFilter.SHARPEN)  # Apply sharpening filter\n",
    "#         image = image.point(lambda x: 0 if x < 150 else 255, '1')  # Fine-tune binarization\n",
    "\n",
    "#         # Tesseract configuration for optimal OCR performance\n",
    "#         custom_config = r'--oem 3 --psm 6'  # Test with other modes like psm 3, 11 for different layouts\n",
    "#         text = pytesseract.image_to_string(image, config=custom_config)\n",
    "#         return text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to extract text from {image_path}: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# # Function to parse key entity values from the extracted text\n",
    "# def parse_entity_values(text):\n",
    "#     # Regular expressions for matching weight, volume, and dimensions\n",
    "#     weight_pattern = r'(\\d+(\\.\\d+)?\\s?(kg|gram|g|mg|pound|lb|ounce|oz))'\n",
    "#     volume_pattern = r'(\\d+(\\.\\d+)?\\s?(ml|l|liter|cup|fluid ounce|fl oz))'\n",
    "#     dimension_pattern = r'(\\d+(\\.\\d+)?\\s?(cm|mm|m|inch|in|feet|ft))'\n",
    "\n",
    "#     weights = re.findall(weight_pattern, text, re.IGNORECASE)\n",
    "#     volumes = re.findall(volume_pattern, text, re.IGNORECASE)\n",
    "#     dimensions = re.findall(dimension_pattern, text, re.IGNORECASE)\n",
    "\n",
    "#     # Extracting and formatting results\n",
    "#     extracted_values = {\n",
    "#         \"weights\": [w[0] for w in weights],\n",
    "#         \"volumes\": [v[0] for v in volumes],\n",
    "#         \"dimensions\": [d[0] for d in dimensions]\n",
    "#     }\n",
    "#     return extracted_values\n",
    "\n",
    "# # Fuzzy matching function to improve alignment\n",
    "# def fuzzy_match(expected, extracted_values):\n",
    "#     best_match = None\n",
    "#     highest_score = 0\n",
    "    \n",
    "#     for key, values in extracted_values.items():\n",
    "#         for value in values:\n",
    "#             # Calculate the match score between the expected value and extracted value\n",
    "#             score = fuzz.partial_ratio(expected.lower(), value.lower())\n",
    "#             if score > highest_score:\n",
    "#                 highest_score = score\n",
    "#                 best_match = value\n",
    "    \n",
    "#     # Consider matches with a high enough score as valid\n",
    "#     return best_match if highest_score > 70 else None\n",
    "\n",
    "# # List all images in the download folder\n",
    "# downloaded_image_paths = list(Path(download_folder).glob(\"*.jpg\"))  # Adjust extension if different\n",
    "\n",
    "# # Dictionary to store OCR results\n",
    "# ocr_results = {}\n",
    "\n",
    "# # Perform OCR and extract entity values for each image\n",
    "# for image_path in tqdm(downloaded_image_paths, desc=\"Extracting OCR\"):\n",
    "#     # Extract text from the image\n",
    "#     extracted_text = extract_text_from_image(image_path)\n",
    "#     # Parse key entity values from the extracted text\n",
    "#     entity_values = parse_entity_values(extracted_text)\n",
    "#     # Store the results\n",
    "#     ocr_results[image_path.name] = entity_values\n",
    "\n",
    "# # Align extracted text with training labels from train.csv\n",
    "# alignment_results = []\n",
    "\n",
    "# for index, row in train_data.iterrows():\n",
    "#     image_name = os.path.basename(row['image_link'])  # Extract the image filename from the path\n",
    "#     entity_name = row['entity_name']\n",
    "#     entity_value = row['entity_value']\n",
    "    \n",
    "#     # Retrieve OCR results for the corresponding image\n",
    "#     if image_name in ocr_results:  # Check if the image name is in OCR results\n",
    "#         extracted_values = ocr_results[image_name]\n",
    "        \n",
    "#         # Use fuzzy matching to find the best match\n",
    "#         matched_value = fuzzy_match(entity_value, extracted_values)\n",
    "        \n",
    "#         alignment_results.append({\n",
    "#             'image_name': image_name,\n",
    "#             'entity_name': entity_name,\n",
    "#             'expected_value': entity_value,\n",
    "#             'extracted_value': matched_value if matched_value else \"No match found\"\n",
    "#         })\n",
    "\n",
    "# # Convert results to DataFrame for easier inspection\n",
    "# alignment_df = pd.DataFrame(alignment_results)\n",
    "\n",
    "# # Display some results\n",
    "# print(alignment_df.head())\n",
    "\n",
    "# # Save results to a CSV file if needed\n",
    "# alignment_df.to_csv(\"alignment_results.csv\", index=False)\n",
    "\n",
    "# print(\"OCR extraction, entity value parsing, and alignment complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "307260f9-dc8c-461e-823b-47afcccd8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['entity_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c02923-bc1f-4de3-a9d3-cd8d6d2297e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "244a2e5c-d62f-4c3a-b62e-b292b338ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Necessary imports (ensure these are included in your environment setup)\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dense, Flatten\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9091ead8-d1bb-415f-800d-7157f7a19697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define U-Net Model with VGG16 Backbone\n",
    "# def unet_with_vgg16(input_shape=(256, 256, 3)):\n",
    "#     vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#     inputs = vgg16.input\n",
    "#     c1 = vgg16.get_layer(\"block1_conv2\").output\n",
    "#     p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "#     c2 = vgg16.get_layer(\"block2_conv2\").output\n",
    "#     p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "#     c3 = vgg16.get_layer(\"block3_conv3\").output\n",
    "#     p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "#     c4 = vgg16.get_layer(\"block4_conv3\").output\n",
    "#     p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "#     c5 = vgg16.get_layer(\"block5_conv3\").output\n",
    "    \n",
    "#     u6 = UpSampling2D((2, 2))(c5)\n",
    "#     u6 = concatenate([u6, c4])\n",
    "#     c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "#     c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "#     u7 = UpSampling2D((2, 2))(c6)\n",
    "#     u7 = concatenate([u7, c3])\n",
    "#     c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "#     c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "#     u8 = UpSampling2D((2, 2))(c7)\n",
    "#     u8 = concatenate([u8, c2])\n",
    "#     c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "#     c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "#     u9 = UpSampling2D((2, 2))(c8)\n",
    "#     u9 = concatenate([u9, c1])\n",
    "#     c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "#     c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "#     outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#     return model\n",
    "\n",
    "# # Compile U-Net Model\n",
    "# input_shape = (256, 256, 3)\n",
    "# unet_model = unet_with_vgg16(input_shape)\n",
    "# unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train U-Net Model (Ensure data directories are set correctly)\n",
    "# train_image_datagen = ImageDataGenerator(rescale=1./255, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2)\n",
    "# train_mask_datagen = ImageDataGenerator(rescale=1./255, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2)\n",
    "\n",
    "# train_image_generator = train_image_datagen.flow_from_directory(\n",
    "#     'train_images/',  # Update with your image directory\n",
    "#     class_mode=None,\n",
    "#     target_size=input_shape[:2],\n",
    "#     batch_size=8,\n",
    "#     seed=42)\n",
    "\n",
    "# train_mask_generator = train_mask_datagen.flow_from_directory(\n",
    "#     'train_masks/',  # Update with your mask directory\n",
    "#     class_mode=None,\n",
    "#     target_size=input_shape[:2],\n",
    "#     batch_size=8,\n",
    "#     seed=42)\n",
    "\n",
    "# train_generator = zip(train_image_generator, train_mask_generator)\n",
    "\n",
    "# # Train U-Net Model\n",
    "# unet_model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=len(train_image_generator),\n",
    "#     epochs=20,\n",
    "#     callbacks=[\n",
    "#         ModelCheckpoint(\"unet_best_model.h5\", save_best_only=True),\n",
    "#         EarlyStopping(patience=5, restore_best_weights=True)\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e6fab0-b2e9-45f3-bc66-926704a45b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccfc780a-e622-4157-be7b-81c1d481c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# import cv2\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# # Define the correct file path\n",
    "# file_path = r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\train.csv\"\n",
    "\n",
    "# # Check if the file exists and load data\n",
    "# if os.path.exists(file_path):\n",
    "#     train_df = pd.read_csv(file_path)\n",
    "#     print(\"File loaded successfully.\")\n",
    "# else:\n",
    "#     raise FileNotFoundError(f\"File not found at path: {file_path}\")\n",
    "\n",
    "# # Helper function to download and preprocess images\n",
    "# def preprocess_image(url, target_size=(224, 224)):\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         img = Image.open(BytesIO(response.content))\n",
    "#         img = img.resize(target_size)\n",
    "#         img = np.array(img) / 255.0  # Normalize\n",
    "#         return img\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image at {url}: {e}\")\n",
    "#         return np.zeros((224, 224, 3))  # Return a blank image on failure\n",
    "\n",
    "# # Preprocess images and labels\n",
    "# train_df['processed_image'] = train_df['image_link'].apply(preprocess_image)\n",
    "# X = np.stack(train_df['processed_image'])\n",
    "# y = train_df['entity_value'].astype(str)  # Convert labels to string format\n",
    "\n",
    "# # Split data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Image data generator for augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # EfficientNetB0 with transfer learning\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# predictions = Dense(1, activation='sigmoid')(x)  # Binary classification, adjust activation if multi-class\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     datagen.flow(X_train, y_train, batch_size=32),\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=20,\n",
    "#     steps_per_epoch=len(X_train) // 32,\n",
    "#     validation_steps=len(X_val) // 32,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "# )\n",
    "\n",
    "# # Evaluate model performance\n",
    "# val_predictions = model.predict(X_val).round().astype(int)\n",
    "# f1 = f1_score(y_val, val_predictions, average='weighted')\n",
    "# precision = precision_score(y_val, val_predictions, average='weighted')\n",
    "# recall = recall_score(y_val, val_predictions, average='weighted')\n",
    "\n",
    "# print(f\"Validation F1 Score: {f1}\")\n",
    "# print(f\"Validation Precision: {precision}\")\n",
    "# print(f\"Validation Recall: {recall}\")\n",
    "\n",
    "# # Load test data and preprocess\n",
    "# test_file_path = r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\test.csv\"\n",
    "# if os.path.exists(test_file_path):\n",
    "#     test_df = pd.read_csv(test_file_path)\n",
    "#     test_df['processed_image'] = test_df['image_link'].apply(preprocess_image)\n",
    "#     X_test = np.stack(test_df['processed_image'])\n",
    "# else:\n",
    "#     raise FileNotFoundError(f\"Test file not found at path: {test_file_path}\")\n",
    "\n",
    "# # Generate predictions for test data\n",
    "# test_predictions = model.predict(X_test).round().astype(int)  # Adjust based on your task\n",
    "\n",
    "# # Format predictions for submission\n",
    "# test_df['prediction'] = [f\"{pred} unit\" for pred in test_predictions]  # Adjust the format as per requirements\n",
    "# output = test_df[['index', 'prediction']]\n",
    "# output.to_csv('test_out.csv', index=False)\n",
    "\n",
    "# # Run sanity check (if available)\n",
    "# # Assuming 'sanity.py' is correctly set up to validate the output format\n",
    "# print(\"Output saved as 'test_out.csv'. Run sanity checks to ensure format validity.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec98065-9b32-4e08-b70b-10538ad1563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# import cv2\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# # Define the correct file paths\n",
    "# train_file_path = r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\train.csv\"\n",
    "# test_file_path = r\"C:\\Users\\HP\\Desktop\\ML_HACKATHON\\test.csv\"\n",
    "\n",
    "# # Load training data\n",
    "# if os.path.exists(train_file_path):\n",
    "#     train_df = pd.read_csv(train_file_path)\n",
    "#     print(\"Training file loaded successfully.\")\n",
    "# else:\n",
    "#     raise FileNotFoundError(f\"Training file not found at path: {train_file_path}\")\n",
    "\n",
    "# # Helper function to download and preprocess images\n",
    "# def preprocess_image(url, target_size=(224, 224)):\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "#         img = img.resize(target_size)\n",
    "#         img = np.array(img) / 255.0  # Normalize\n",
    "#         return img\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image at {url}: {e}\")\n",
    "#         return np.zeros((224, 224, 3))  # Return a blank image on failure\n",
    "\n",
    "# # Preprocess images and labels\n",
    "# train_df['processed_image'] = train_df['image_link'].apply(preprocess_image)\n",
    "# X = np.stack(train_df['processed_image'])\n",
    "# y = train_df['entity_value'].astype(str)  # Convert labels to string format\n",
    "\n",
    "# # Split data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Image data generator for augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # EfficientNetB0 with transfer learning\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# predictions = Dense(1, activation='sigmoid')(x)  # Adjust for binary classification; modify for multi-class if needed\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     datagen.flow(X_train, y_train, batch_size=32),\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=20,\n",
    "#     steps_per_epoch=len(X_train) // 32,\n",
    "#     validation_steps=len(X_val) // 32,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "# )\n",
    "\n",
    "# # Evaluate model performance\n",
    "# val_predictions = model.predict(X_val).round().astype(int)\n",
    "# f1 = f1_score(y_val, val_predictions, average='weighted')\n",
    "# precision = precision_score(y_val, val_predictions, average='weighted')\n",
    "# recall = recall_score(y_val, val_predictions, average='weighted')\n",
    "\n",
    "# print(f\"Validation F1 Score: {f1}\")\n",
    "# print(f\"Validation Precision: {precision}\")\n",
    "# print(f\"Validation Recall: {recall}\")\n",
    "\n",
    "# # Load and preprocess test data\n",
    "# if os.path.exists(test_file_path):\n",
    "#     test_df = pd.read_csv(test_file_path)\n",
    "#     test_df['processed_image'] = test_df['image_link'].apply(preprocess_image)\n",
    "#     X_test = np.stack(test_df['processed_image'])\n",
    "#     print(\"Test file loaded and preprocessed successfully.\")\n",
    "# else:\n",
    "#     raise FileNotFoundError(f\"Test file not found at path: {test_file_path}\")\n",
    "\n",
    "# # Generate predictions for test data\n",
    "# test_predictions = model.predict(X_test).round().astype(int)  # Adjust based on your task\n",
    "# test_df['prediction'] = [f\"{pred[0]} unit\" for pred in test_predictions]  # Format predictions as required\n",
    "\n",
    "# # Save output in the required format\n",
    "# output = test_df[['index', 'prediction']]\n",
    "# output.to_csv('test_out.csv', index=False)\n",
    "# print(\"Output saved as 'test_out.csv'. Run sanity checks to ensure format validity.\")\n",
    "\n",
    "# # Optionally, run sanity checks using provided scripts\n",
    "# # Ensure the output is formatted correctly before submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ada2acad-d89e-49db-9e47-39dd2a1f4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # Define the command to run the sanity check script\n",
    "# sanity_check_script = r\"sanity.py\"  # Ensure this is the correct path to your sanity check script\n",
    "# output_file = 'test_out.csv'  # Path to the output file you want to check\n",
    "\n",
    "# # Run the sanity check\n",
    "# try:\n",
    "#     result = subprocess.run(\n",
    "#         ['python', sanity_check_script, output_file],\n",
    "#         check=True,\n",
    "#         capture_output=True,\n",
    "#         text=True\n",
    "#     )\n",
    "#     print(\"Sanity check output:\")\n",
    "#     print(result.stdout)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(\"Sanity check failed:\")\n",
    "#     print(e.output)\n",
    "#     print(e.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4176471-aba9-442c-ba89-ff9b572fea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, concatenate, Dropout, UpSampling2D\n",
    "\n",
    "def unet_with_pretrained_encoder(input_shape=(256, 256, 3)):\n",
    "    # Load a pre-trained model as the encoder\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Use the layers of the pre-trained model\n",
    "    encoder_layers = [base_model.get_layer(name).output for name in ['block1_pool', 'block2_pool', 'block3_pool', 'block4_pool']]\n",
    "    \n",
    "    # Define the input layer\n",
    "    inputs = base_model.input\n",
    "    \n",
    "    # Decoder part of the U-Net\n",
    "    x = encoder_layers[-1]  # Start from the deepest layer\n",
    "    \n",
    "    # Upsampling and concatenating with corresponding encoder layers\n",
    "    for i in range(3, 0, -1):\n",
    "        x = Conv2DTranspose(256 // (2 ** i), (3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = concatenate([x, encoder_layers[i-1]])\n",
    "        x = Conv2D(256 // (2 ** i), (3, 3), activation='relu', padding='same')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "    # Final layer to match the mask output\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "unet_model = unet_with_pretrained_encoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8213968-a54a-482a-8bce-493c344208ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# # Function to load images from a file path and prepare them for the model\n",
    "# def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if image is None:\n",
    "#         print(f\"Error loading image: {image_path}\")\n",
    "#         return None\n",
    "#     image = cv2.resize(image, target_size)\n",
    "#     image = image / 255.0  # Normalize the image\n",
    "#     return image\n",
    "\n",
    "# # Function to generate masks using the U-Net model\n",
    "# def generate_masks(unet_model, csv_file, image_directory, output_directory, target_size=(256, 256)):\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file)\n",
    "    \n",
    "#     # Ensure the output directory exists\n",
    "#     if not os.path.exists(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "        \n",
    "#     # Iterate through the image paths in the CSV\n",
    "#     for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\"):\n",
    "#         image_link = row['image_link']\n",
    "#         image_filename = os.path.basename(image_link)  # Extract the image filename from the URL\n",
    "#         image_path = os.path.join(image_directory, image_filename)\n",
    "        \n",
    "#         # Check if the image exists locally\n",
    "#         if os.path.exists(image_path):\n",
    "#             # Load and preprocess the image\n",
    "#             image = load_and_preprocess_image(image_path, target_size)\n",
    "#             if image is None:\n",
    "#                 continue\n",
    "            \n",
    "#             image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "#             # Predict mask\n",
    "#             predicted_mask = unet_model.predict(image)[0]\n",
    "\n",
    "#             # Convert prediction to binary mask\n",
    "#             binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "#             # Save mask with the same filename as the input image\n",
    "#             mask_filename = os.path.splitext(image_filename)[0] + '.png'  # Save as PNG\n",
    "#             mask_path = os.path.join(output_directory, mask_filename)\n",
    "#             cv2.imwrite(mask_path, binary_mask)\n",
    "#         else:\n",
    "#             print(f\"Image not found: {image_path}\")\n",
    "\n",
    "# # Use the function to generate masks\n",
    "# # Ensure 'train.csv' has a column named 'image_link' with the image filenames\n",
    "# generate_masks(unet_model, 'train.csv', \"C:/Users/HP/Desktop/ML_HACKATHON/imgs\", 'train_masks/')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "115b2d2e-5632-48bb-9ab9-11a60268ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Images: 100%|| 100/100 [00:00<00:00, 2084.08it/s]\n",
      "Generating Masks:   0%|                                                                         | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   1%|                                                                | 1/99 [00:01<02:45,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   2%|                                                               | 2/99 [00:02<01:47,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   3%|                                                               | 3/99 [00:03<01:28,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   4%|                                                              | 4/99 [00:03<01:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   5%|                                                             | 5/99 [00:04<01:12,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   6%|                                                             | 6/99 [00:05<01:09,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   7%|                                                            | 7/99 [00:05<01:07,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   8%|                                                           | 8/99 [00:06<01:04,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:   9%|                                                           | 9/99 [00:07<01:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  10%|                                                         | 10/99 [00:07<01:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  11%|                                                         | 11/99 [00:08<01:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  12%|                                                        | 12/99 [00:09<01:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  13%|                                                       | 13/99 [00:10<01:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  14%|                                                       | 14/99 [00:10<01:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  15%|                                                      | 15/99 [00:11<01:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  16%|                                                     | 16/99 [00:12<00:59,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  17%|                                                     | 17/99 [00:13<00:59,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  18%|                                                    | 18/99 [00:13<00:56,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  19%|                                                   | 19/99 [00:14<00:56,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  20%|                                                   | 20/99 [00:15<00:56,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  21%|                                                  | 21/99 [00:15<00:54,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  22%|                                                 | 22/99 [00:16<00:54,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  23%|                                                 | 23/99 [00:17<00:53,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  24%|                                                | 24/99 [00:17<00:52,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  25%|                                               | 25/99 [00:18<00:52,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  26%|                                               | 26/99 [00:19<00:52,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  27%|                                              | 27/99 [00:20<00:51,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  28%|                                              | 28/99 [00:20<00:50,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  29%|                                             | 29/99 [00:21<00:50,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  30%|                                            | 30/99 [00:22<00:48,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  31%|                                            | 31/99 [00:22<00:47,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  32%|                                           | 32/99 [00:23<00:47,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  33%|                                          | 33/99 [00:24<00:47,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  34%|                                          | 34/99 [00:24<00:45,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  35%|                                         | 35/99 [00:25<00:44,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  36%|                                        | 36/99 [00:26<00:45,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  37%|                                        | 37/99 [00:27<00:45,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  38%|                                       | 38/99 [00:27<00:44,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  39%|                                      | 39/99 [00:28<00:42,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  40%|                                      | 40/99 [00:29<00:44,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  41%|                                     | 41/99 [00:30<00:42,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  42%|                                    | 42/99 [00:30<00:40,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  43%|                                    | 43/99 [00:31<00:39,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  44%|                                   | 44/99 [00:32<00:38,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  45%|                                   | 45/99 [00:32<00:37,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  46%|                                  | 46/99 [00:33<00:38,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  47%|                                 | 47/99 [00:34<00:38,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  48%|                                 | 48/99 [00:35<00:38,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  49%|                                | 49/99 [00:35<00:37,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  51%|                               | 50/99 [00:36<00:36,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  52%|                               | 51/99 [00:37<00:36,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  53%|                              | 52/99 [00:38<00:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  54%|                             | 53/99 [00:38<00:34,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  55%|                             | 54/99 [00:39<00:33,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  56%|                            | 55/99 [00:40<00:32,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  57%|                           | 56/99 [00:41<00:31,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  58%|                           | 57/99 [00:42<00:32,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  59%|                          | 58/99 [00:42<00:31,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  60%|                         | 59/99 [00:43<00:30,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  61%|                         | 60/99 [00:44<00:29,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  62%|                        | 61/99 [00:44<00:28,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  63%|                        | 62/99 [00:45<00:27,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  64%|                       | 63/99 [00:46<00:27,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  65%|                      | 64/99 [00:47<00:27,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  66%|                      | 65/99 [00:48<00:26,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  67%|                     | 66/99 [00:48<00:25,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  68%|                    | 67/99 [00:49<00:23,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  69%|                    | 68/99 [00:50<00:23,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  70%|                   | 69/99 [00:51<00:22,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  71%|                  | 70/99 [00:51<00:21,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  72%|                  | 71/99 [00:52<00:20,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  73%|                 | 72/99 [00:53<00:19,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  74%|                | 73/99 [00:53<00:19,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  75%|                | 74/99 [00:54<00:18,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  76%|               | 75/99 [00:55<00:17,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  77%|              | 76/99 [00:56<00:16,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  78%|              | 77/99 [00:56<00:16,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  79%|             | 78/99 [00:57<00:15,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  80%|             | 79/99 [00:58<00:15,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  81%|            | 80/99 [00:59<00:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  82%|           | 81/99 [01:00<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  83%|           | 82/99 [01:01<00:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  84%|          | 83/99 [01:01<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  85%|         | 84/99 [01:02<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  86%|         | 85/99 [01:03<00:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  87%|        | 86/99 [01:04<00:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  88%|       | 87/99 [01:04<00:08,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  89%|       | 88/99 [01:05<00:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  90%|      | 89/99 [01:06<00:07,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  91%|     | 90/99 [01:07<00:06,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  92%|     | 91/99 [01:07<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  93%|    | 92/99 [01:08<00:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  94%|    | 93/99 [01:09<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  95%|   | 94/99 [01:10<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  96%|  | 95/99 [01:11<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  97%|  | 96/99 [01:12<00:02,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks:  98%| | 97/99 [01:13<00:01,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Masks: 100%|| 99/99 [01:13<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: C:/Users/HP/Desktop/ML_HACKATHON/newimgg\\class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Define the new download folder path\n",
    "download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/newimgg\"\n",
    "\n",
    "# Function to create a placeholder image\n",
    "def create_placeholder_image(image_save_path):\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "        placeholder_image.save(image_save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating placeholder image: {e}\")\n",
    "\n",
    "# Function to download images from URLs\n",
    "def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "    if not isinstance(image_link, str):\n",
    "        return\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            response = requests.get(image_link, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(image_save_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(1024):\n",
    "                        f.write(chunk)\n",
    "                return\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {image_link}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    create_placeholder_image(image_save_path)  # Create a black placeholder image for invalid links/images\n",
    "\n",
    "# Function to download the top 100 images\n",
    "def download_top_images(csv_file, download_folder, top_n=100):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Ensure the download directory exists\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    # Get the top 100 image links\n",
    "    image_links = df['image_link'].head(top_n)\n",
    "    \n",
    "    # Download images\n",
    "    for image_link in tqdm(image_links, desc=\"Downloading Images\"):\n",
    "        download_image(image_link, download_folder)\n",
    "\n",
    "# Function to load images from a file path and prepare them for the model\n",
    "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return None\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Function to generate masks using the U-Net model\n",
    "def generate_masks(unet_model, image_directory, output_directory, target_size=(256, 256)):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        \n",
    "    # Iterate through the images in the directory\n",
    "    for image_filename in tqdm(os.listdir(image_directory), desc=\"Generating Masks\"):\n",
    "        image_path = os.path.join(image_directory, image_filename)\n",
    "        \n",
    "        # Check if the image exists locally\n",
    "        if os.path.exists(image_path):\n",
    "            # Load and preprocess the image\n",
    "            image = load_and_preprocess_image(image_path, target_size)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "            # Predict mask\n",
    "            predicted_mask = unet_model.predict(image)[0]\n",
    "\n",
    "            # Convert prediction to binary mask\n",
    "            binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "            # Save mask with the same filename as the input image\n",
    "            mask_filename = os.path.splitext(image_filename)[0] + '.png'  # Save as PNG\n",
    "            mask_path = os.path.join(output_directory, mask_filename)\n",
    "            cv2.imwrite(mask_path, binary_mask)\n",
    "        else:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "\n",
    "# Step 1: Download the top 100 images from the CSV file to the specified folder\n",
    "download_top_images('train.csv', download_folder, top_n=100)\n",
    "\n",
    "# Step 2: Generate masks for the downloaded images\n",
    "generate_masks(unet_model, download_folder, 'train_masks/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303e6665-dc16-432e-a0ca-d8a5614f0900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
       "\n",
       " input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span>  conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span>  conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " max_pooling2d_1                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span>  max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span>  conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " max_pooling2d_2                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span>  conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " max_pooling2d_3                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span>  max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span>  conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  up_sampling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
       "                                                                            conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">7,078,400</span>  concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span>  conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " up_sampling2d_1                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)                                                                                        \n",
       "\n",
       " concatenate_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  up_sampling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       "                                                                            conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,728</span>  concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span>  conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " up_sampling2d_2                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)                                                                                        \n",
       "\n",
       " concatenate_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  up_sampling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       "                                                                            conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span>  concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span>  conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " up_sampling2d_3                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)                                                                                        \n",
       "\n",
       " concatenate_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  up_sampling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       "                                                                            conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       "\n",
       " conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span>  concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span>  conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>  conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m1,792\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m36,928\u001b[0m  conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m73,856\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m147,584\u001b[0m  conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " max_pooling2d_1                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m295,168\u001b[0m  max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m590,080\u001b[0m  conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " max_pooling2d_2                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m1,180,160\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m2,359,808\u001b[0m  conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " max_pooling2d_3                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             \u001b[38;5;34m4,719,616\u001b[0m  max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             \u001b[38;5;34m9,438,208\u001b[0m  conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1536\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  up_sampling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
       "                                                                            conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m7,078,400\u001b[0m  concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m2,359,808\u001b[0m  conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " up_sampling2d_1                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mUpSampling2D\u001b[0m)                                                                                        \n",
       "\n",
       " concatenate_4 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m768\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  up_sampling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       "                                                                            conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)              \u001b[38;5;34m1,769,728\u001b[0m  concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m590,080\u001b[0m  conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " up_sampling2d_2                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mUpSampling2D\u001b[0m)                                                                                        \n",
       "\n",
       " concatenate_5 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m384\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  up_sampling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       "                                                                            conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m442,496\u001b[0m  concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m147,584\u001b[0m  conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " up_sampling2d_3                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mUpSampling2D\u001b[0m)                                                                                        \n",
       "\n",
       " concatenate_6 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m192\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  up_sampling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       "                                                                            conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       "\n",
       " conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)               \u001b[38;5;34m110,656\u001b[0m  concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m36,928\u001b[0m  conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     \u001b[38;5;34m65\u001b[0m  conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,378,945</span> (119.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,378,945\u001b[0m (119.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,378,945</span> (119.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,378,945\u001b[0m (119.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "\n",
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the U-Net model\n",
    "unet_model = unet_model(input_size=(256, 256, 3))\n",
    "unet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b547d-ac56-4c39-a09e-b52667579a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a custom generator to use U-Net for generating masks on the fly\n",
    "def image_generator_with_generated_masks(model, image_folder, batch_size, target_size=(256, 256)):\n",
    "    # Define the ImageDataGenerator for images\n",
    "    image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Load images from the directory, ensuring the correct subdirectory structure\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        image_folder, \n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No labels needed, just images\n",
    "        seed=42,\n",
    "        color_mode='rgb'  # Assuming images are in RGB format\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        # Use __next__() to get the next batch of images\n",
    "        images = image_generator.__next__()\n",
    "        generated_masks = []\n",
    "\n",
    "        # Generate masks using the model\n",
    "        for img in images:\n",
    "            img_array = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "            predicted_mask = model.predict(img_array)  # Generate mask\n",
    "            predicted_mask = (predicted_mask > 0.5).astype(np.float32)  # Threshold the mask\n",
    "            generated_masks.append(predicted_mask[0])  # Remove batch dimension\n",
    "\n",
    "        yield images, np.array(generated_masks)  # Yield images and generated masks as a tuple\n",
    "\n",
    "# Define paths\n",
    "download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/newimgg\"  # Path to images with subdirectory 'class1'\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Ensure that 'unet_model' is defined and compiled before this point\n",
    "# Example: unet_model = ... (your U-Net model initialization code here)\n",
    "\n",
    "# Initialize the custom generator\n",
    "train_generator = image_generator_with_generated_masks(unet_model, download_folder, batch_size)\n",
    "\n",
    "# Verify generator output before training\n",
    "import traceback\n",
    "\n",
    "try:\n",
    "    sample_images, sample_masks = next(train_generator)\n",
    "    print(f\"Sample images shape: {sample_images.shape}\")\n",
    "    print(f\"Sample masks shape: {sample_masks.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in generator output: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Check that the subdirectory 'class1' exists and contains images\n",
    "steps_per_epoch = max(1, len(os.listdir(os.path.join(download_folder, 'class1'))) // batch_size)\n",
    "\n",
    "# Train the U-Net model using generated masks directly\n",
    "unet_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  # Ensure this matches the number of available images\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"unet_best_weights.weights.h5\", save_best_only=True, save_weights_only=True),  # Save weights only with correct extension\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88608a9e-f525-4c83-b4f2-3b10f121821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "\n",
    "# def unet_model(input_size=(256, 256, 3)):\n",
    "#     inputs = Input(input_size)\n",
    "\n",
    "#     # Encoder\n",
    "#     c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "#     p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "#     c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "#     c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "#     p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "#     c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "#     c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "#     p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "#     c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "#     c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "#     p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "#     c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "#     # Decoder\n",
    "#     u6 = UpSampling2D((2, 2))(c5)\n",
    "#     u6 = Concatenate()([u6, c4])\n",
    "#     c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "#     c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "#     u7 = UpSampling2D((2, 2))(c6)\n",
    "#     u7 = Concatenate()([u7, c3])\n",
    "#     c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "#     c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "#     u8 = UpSampling2D((2, 2))(c7)\n",
    "#     u8 = Concatenate()([u8, c2])\n",
    "#     c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "#     c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "#     u9 = UpSampling2D((2, 2))(c8)\n",
    "#     u9 = Concatenate()([u9, c1])\n",
    "#     c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "#     c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "#     outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the U-Net model\n",
    "# unet_model = unet_model(input_size=(256, 256, 3))\n",
    "# unet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b14c0-2e44-499d-ab92-9d865fbb602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Define paths\n",
    "# download_folder = \"C:/Users/HP/Desktop/ML_HACKATHON/newimgg\"  # Path to images\n",
    "# batch_size = 8\n",
    "\n",
    "# # Assuming the train_generator is already defined as per previous code\n",
    "# # Train the U-Net model using generated masks directly\n",
    "# unet_model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=len(os.listdir(download_folder)) // batch_size,  # Adjust this if images are within subdirectories\n",
    "#     epochs=5,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.ModelCheckpoint(\"unet_best_weights.weights.h5\", save_best_only=True, save_weights_only=True),  # Updated extension to .weights.h5\n",
    "#         tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b6f4d-6878-4521-84ed-e6a2666d7733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0275a0-0ad7-44f1-8c50-fc9d500766fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53a978-f2e4-46c8-810a-3a8d3ffe7724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf1381-02f4-4693-9ac6-ab42a67dfe09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aac318-6385-467e-b687-25aa8399b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cff1b5-d4b4-4127-a947-3938f312ac93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea405b5-9194-4ca5-aaca-c5d97a68f390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10893c6-d031-4faa-b102-20773a463780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
